{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we create different PCA models (i.e. trained on different data / different function parameters) which we save and can later re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'models/pca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X = load_and_flatten_hsi('../Data/HDF5_FILES/train', mask_dir='../Data/MASKS/train', apply_mask=True, individual_normalize=False, mask_method=1)\n",
    "print(f\"Data shape before PCA: {X.shape}\")\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.995)    # Retain 99.5% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Print results\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Number of components chosen: {pca.n_components_}\")\n",
    "print(f\"Explained variance ratio: {explained_variance_ratio[-1]:.4f}\")\n",
    "print(f\"Data shape after PCA: {X_pca.shape}\")\n",
    "\n",
    "# Save PCA model and scaler\n",
    "joblib.dump(pca, os.path.join(save_path, 'first_pca_model.pkl'))    # TODO: Maybe change pkl to joblib\n",
    "joblib.dump(scaler, os.path.join(save_path, 'first_scaler.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loadings\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "# Plot PC loadings\n",
    "_, wlens = LoadHSI('../Data/HDF5_FILES/train/FX10_07SEPT2023_1B1.hdf5', return_wlens=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(pca.n_components_):\n",
    "    plt.plot(wlens, loadings[:, i], label=f'PC {i+1}')\n",
    "\n",
    "plt.xlabel('Wavelength (nm)')\n",
    "plt.ylabel('Loading Value')\n",
    "plt.title('Principal Component Loadings')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
