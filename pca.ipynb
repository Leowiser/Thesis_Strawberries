{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi_np, wlens = LoadHSI('../Data/HDF5_FILES/train/FX10_07SEPT2023_1B1.hdf5', return_wlens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_np = read_mask('../Data/MASKS/train/FX10_07SEPT2023_1B1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_flatten_hsi(img_dir, mask_dir=None, individual_normalize=False, apply_mask=False, mask_method=1):\n",
    "    \"\"\"\n",
    "    Transforms the 3D hyperspectral images into a 2D array by flattening the spatial dimensions. The resulting \"rows\" are the pixels\n",
    "    and the \"columns\" store their values for the different spectral bands. \n",
    "    Can be used with a single- or multiple HSI-s. If multiple HSI-s are provided, they are stacked together.\n",
    "\n",
    "    Parameters:\n",
    "    - img_dir: str, path to the folder containing the HSI-s\n",
    "    - mask_dir: str, path to the folder containing the masks for the HSI-s\n",
    "    - individual_normalize: bool, whether to normalize each HSI individually before flattening and stacking\n",
    "    - apply_mask: bool, whether to apply the mask to the HSI-s\n",
    "    - mask_method: int, 0 for keeping only leaf, 1 for keeping leaf+stem after applying the mask\n",
    "\n",
    "    Returns:\n",
    "    - numpy array, shape (n_pixels, n_bands), the flattened and stacked HSI pixels\n",
    "    \"\"\"\n",
    "    all_pixels = []\n",
    "    \n",
    "    for file in os.listdir(img_dir):\n",
    "        hsi_np = LoadHSI(os.path.join(img_dir, file))\n",
    "        \n",
    "        # Set all negative values to 0 (these are noise)\n",
    "        hsi_np = np.maximum(hsi_np, 0)\n",
    "        \n",
    "        # Load mask if required\n",
    "        if apply_mask and mask_dir:\n",
    "            mask_file = os.path.join(mask_dir, os.path.splitext(file)[0] + \".png\")    # Find the mask for the HSI (same name)\n",
    "            mask_np = read_mask(mask_file)\n",
    "            hsi_np = hsi_np * np.where(mask_np == 2, mask_method, mask_np)\n",
    "\n",
    "        # Flatten: (bands, height, width) → (height*width, bands)\n",
    "        hsi_np = hsi_np.reshape(hsi_np.shape[0], -1).T\n",
    "        \n",
    "        # Apply mask if required - Remove background (zero) pixels\n",
    "        if apply_mask:\n",
    "            hsi_np = hsi_np[~np.all(hsi_np == 0, axis=1)]\n",
    "        \n",
    "        # Normalize each image individually if required\n",
    "        if individual_normalize:\n",
    "            hsi_np = hsi_np / np.max(hsi_np)\n",
    "\n",
    "        all_pixels.append(hsi_np)\n",
    "    \n",
    "    # Stack all pixels together\n",
    "    return np.vstack(all_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X = load_and_flatten_hsi('../Data/HDF5_FILES/train', mask_dir='../Data/MASKS/train', apply_mask=True, individual_normalize=False, mask_method=1)\n",
    "print(f\"Data shape before PCA: {X.shape}\")\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.995)    # Retain 99.5% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Print results\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Number of components chosen: {pca.n_components_}\")\n",
    "print(f\"Explained variance ratio: {explained_variance_ratio[-1]:.4f}\")\n",
    "print(f\"Data shape after PCA: {X_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loadings\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "# Plot PC loadings\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(pca.n_components_):\n",
    "    plt.plot(wlens, loadings[:, i], label=f'PC {i+1}')\n",
    "\n",
    "plt.xlabel('Wavelength (nm)')\n",
    "plt.ylabel('Loading Value')\n",
    "plt.title('Principal Component Loadings')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_spectra(X, wlens):\n",
    "    # Initialize a list to store spectral values for averaging\n",
    "    all_spectral_values = []\n",
    "    \n",
    "    # Plot the spectral values for the pixels\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(len(X)):\n",
    "        all_spectral_values.append(X[i])  # Collect spectral values\n",
    "        plt.plot(wlens, X[i], color='lightblue', linewidth=0.4, alpha=0.3)  # Blue color with reduced transparency\n",
    "        \n",
    "    # Convert the list to a numpy array for easier statistical computation\n",
    "    all_spectral_values = np.array(all_spectral_values)\n",
    "    \n",
    "    # Compute the mean and standard deviation\n",
    "    mean_spectral_values = np.mean(all_spectral_values, axis=0)\n",
    "    std_spectral_values = np.std(all_spectral_values, axis=0)\n",
    "    \n",
    "    # Plot the mean spectral values as a thick dark blue line\n",
    "    plt.plot(wlens, mean_spectral_values, color='darkblue', linewidth=3, label='Mean Spectral Value')\n",
    "    \n",
    "    # Plot the standard deviation as shaded areas around the mean (dark blue with transparency)\n",
    "    plt.fill_between(\n",
    "        wlens, \n",
    "        mean_spectral_values - std_spectral_values, \n",
    "        mean_spectral_values + std_spectral_values, \n",
    "        color='darkblue', alpha=0.5, label='±1 Std Dev'\n",
    "    )\n",
    "    \n",
    "    # Customize ticks on both axes\n",
    "    ax = plt.gca()\n",
    "    # X-axis ticks\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(100))  # Big ticks every 100\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(10))   # Small ticks every 20\n",
    "    # Y-axis ticks\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(5000))  # Big ticks every 5000\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(1000)) # Small ticks every 1000\n",
    "\n",
    "    # Add titles, labels, and legend\n",
    "    plt.xlabel('Wavelength (nm)')\n",
    "    plt.ylabel('Reflectance')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct PCA\n",
    "X_reconstructed = pca.inverse_transform(X_pca)\n",
    "X_reconstructed = scaler.inverse_transform(X_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_pca.shape)\n",
    "print(X_reconstructed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "plot_spectra(X[5000:10000], wlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructed\n",
    "plot_spectra(X_reconstructed[5000:10000], wlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsi_transform_to_pca_space(hsi_np, pca, scaler, mask_np=None, mask_method=1):\n",
    "    \"\"\"\n",
    "    Apply pre-trained PCA on HSI to reduce spectral bands, i.e. transform data to PCA space.\n",
    "    If a mask is provided, only the valid non-background pixels are transformed to the PCA space with the pre-trained PCA model. Also,\n",
    "    the background pixels will be set to 0 in the PCA space as well.\n",
    "\n",
    "    Parameters:\n",
    "    - hsi_np: numpy array, Hyperspectral image with shape (bands, height, width).\n",
    "    - pca: Pre-fitted PCA model.\n",
    "    - scaler: Pre-fitted StandardScaler model.\n",
    "    - mask_np: numpy array, mask to apply on the HSI.\n",
    "    - mask_method: int, 0 for keeping only leaf, 1 for keeping leaf+stem after applying the mask.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of PCA-transformed HSI with shape (pca_components, height, width).\n",
    "    \"\"\"\n",
    "    # Set all negative values to 0 (these are noise)\n",
    "    # hsi_np = np.maximum(hsi_np, 0)    # Q: Interestingly if we do this, the reconstruction errors show vertical lines\n",
    "    # A: Because we would need to change negative values to 0 in the function that calculates reconstruction error as well to the\n",
    "    # \"original\" hsi_np that we compare the reconstructed to. → Better apply np.maximum(hsi_np, 0) before calling the function and not inside it.\n",
    "    \n",
    "    # Flatten: (bands, height, width) → (height*width, bands)\n",
    "    hsi_flattened = hsi_np.reshape(hsi_np.shape[0], -1).T\n",
    "    \n",
    "    # Apply mask if provided (exclude background from PCA)\n",
    "    if mask_np is not None:\n",
    "        mask_np = np.where(mask_np == 2, mask_method, mask_np)\n",
    "        valid_indices = mask_np.flatten() != 0\n",
    "        hsi_valid = hsi_flattened[valid_indices]    # Keep only non-background pixels\n",
    "    else:\n",
    "        hsi_valid = hsi_flattened\n",
    "\n",
    "    # Standardize using the previously fitted scaler\n",
    "    hsi_valid_scaled = scaler.transform(hsi_valid)\n",
    "\n",
    "    # Apply the pre-trained PCA model\n",
    "    hsi_pca_valid = pca.transform(hsi_valid_scaled)\n",
    "\n",
    "    # Return to the original number of pixels, with 0s for background pixels if mask was applied and PCA-transformed pixels for the rest\n",
    "    if mask_np is not None:\n",
    "        hsi_pca = np.zeros((hsi_flattened.shape[0], pca.n_components_))    # Initialize empty array with the shape of the original pixels\n",
    "        hsi_pca[valid_indices] = hsi_pca_valid    # Insert only valid transformed pixels\n",
    "    else:\n",
    "        hsi_pca = hsi_pca_valid    # No mask applied, just return transformed pixels\n",
    "\n",
    "    # Reshape back to (pca_components, height, width)\n",
    "    return hsi_pca.T.reshape(pca.n_components_, hsi_np.shape[1], hsi_np.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_hsi_from_pca_space(hsi_pca, pca, scaler, mask_np=None, mask_method=1):\n",
    "    \"\"\"\n",
    "    Back-transform PCA-transformed HSI to original space.\n",
    "    If a mask is provided, only the valid non-background pixels are reconstructed from the PCA space to the original space, with background\n",
    "    pixels set to 0.\n",
    "    \n",
    "    Parameters:\n",
    "    - hsi_pca: numpy array, PCA-transformed HSI with shape (pca_components, height, width).\n",
    "    - pca: Pre-fitted PCA model.\n",
    "    - scaler: Pre-fitted StandardScaler model.\n",
    "    - mask_np: numpy array, mask to apply on the HSI.\n",
    "    - mask_method: int, 0 for keeping only leaf, 1 for keeping leaf+stem after applying the mask.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of back-transformed (reconstructed) HSI with shape (bands, height, width).\n",
    "    \"\"\"\n",
    "    # Flatten: (pca_components, height, width) → (height*width, pca_components)\n",
    "    hsi_pca_flattened = hsi_pca.reshape(pca.n_components_, -1).T\n",
    "    \n",
    "    # Apply mask if provided (exclude background from PCA)\n",
    "    if mask_np is not None:\n",
    "        mask_np = np.where(mask_np == 2, mask_method, mask_np)\n",
    "        valid_indices = mask_np.flatten() != 0\n",
    "        hsi_valid = hsi_pca_flattened[valid_indices]    # Keep only non-background pixels\n",
    "    else:\n",
    "        hsi_valid = hsi_pca_flattened\n",
    "\n",
    "    # Apply inverse PCA\n",
    "    hsi_valid_reconstructed = pca.inverse_transform(hsi_valid)\n",
    "\n",
    "    # Apply inverse scaling\n",
    "    hsi_valid_reconstructed = scaler.inverse_transform(hsi_valid_reconstructed)\n",
    "    \n",
    "    # Reconstruct full spatial structure if mask was applied\n",
    "    if mask_np is not None:\n",
    "        hsi_reconstructed = np.zeros((hsi_pca_flattened.shape[0], hsi_valid_reconstructed.shape[1]))    # Initialize empty array of shape (original pixels, original bands)\n",
    "        hsi_reconstructed[valid_indices] = hsi_valid_reconstructed    # Insert only valid transformed pixels\n",
    "    else:\n",
    "        hsi_reconstructed = hsi_valid_reconstructed    # No mask applied, just return reconstructed pixels\n",
    "\n",
    "    # Reshape back to (bands, height, width)\n",
    "    return hsi_reconstructed.T.reshape(-1, hsi_pca.shape[1], hsi_pca.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_and_reconstruct_hsi_pca(hsi_np, pca, scaler, mask_np=None, mask_method=1):\n",
    "    '''\n",
    "    Preform PCA compression and reconstruction right after on a HSI data.\n",
    "    \n",
    "    Parameters:\n",
    "    - hsi_np: numpy array, Hyperspectral image with shape (bands, height, width).\n",
    "    - pca: Pre-fitted PCA model.\n",
    "    - scaler: Pre-fitted StandardScaler model.\n",
    "    - mask_np: numpy array, mask to apply on the HSI.\n",
    "    - mask_method: int, 0 for keeping only leaf, 1 for keeping leaf+stem after applying the mask.    \n",
    "    '''\n",
    "    # Transform data to PCA space\n",
    "    hsi_pca = hsi_transform_to_pca_space(hsi_np, pca, scaler, mask_np, mask_method)\n",
    "    \n",
    "    # Reconstruct data from PCA space\n",
    "    hsi_reconstructed = reconstruct_hsi_from_pca_space(hsi_pca, pca, scaler, mask_np, mask_method)\n",
    "    \n",
    "    return hsi_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_reconstruction_error(hsi_np, pca, scaler, mask_np=None, mask_method=1):\n",
    "    \"\"\"\n",
    "    Reconstruct an input HSI using the pre-trained PCA and plot the reconstruction error.\n",
    "    Should be used with a single HSI file.\n",
    "\n",
    "    Parameters:\n",
    "    - hsi_np: numpy array, Hyperspectral image with shape (bands, height, width)\n",
    "    - pca: pre-fitted PCA model\n",
    "    - scaler: pre-fitted StandardScaler model\n",
    "    - mask_np: numpy array, mask to apply on the HSI\n",
    "    - mask_method: int, 0 for keeping only leaf, 1 for keeping leaf+stem after applying the mask\n",
    "\n",
    "    Returns:\n",
    "    - Plot (\"heatmap\") of the sum of reconstruction errors across the bands\n",
    "    \"\"\"\n",
    "    # Apply PCA and reconstruct\n",
    "    hsi_pca = hsi_transform_to_pca_space(hsi_np, pca, scaler, mask_np, mask_method)\n",
    "    hsi_reconstructed = reconstruct_hsi_from_pca_space(hsi_pca, pca, scaler, mask_np, mask_method)\n",
    "    \n",
    "    # Compute reconstruction error\n",
    "    if mask_np is not None:\n",
    "        mask_np = np.where(mask_np == 2, mask_method, mask_np)\n",
    "        reconstruction_error = np.abs(hsi_np - hsi_reconstructed) * mask_np\n",
    "    else:\n",
    "        reconstruction_error = np.abs(hsi_np - hsi_reconstructed)\n",
    "\n",
    "    # Sum reconstruction error across the bands\n",
    "    pixel_errors = np.sum(reconstruction_error, axis=0)\n",
    "\n",
    "    # Plot pixel errors\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(pixel_errors, cmap='hot')\n",
    "    plt.colorbar(label='Total Reconstruction Error')\n",
    "    plt.title('Total Reconstruction Error per Pixel')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_reconstruction_error_dir(hsi_path, pca, scaler, mask_dir=None, apply_mask=False, mask_method=1):\n",
    "    \"\"\"\n",
    "    Reconstruct an input HSI using the pre-trained PCA and plot the reconstruction error.\n",
    "    Should be used with a single HSI file.\n",
    "    Since the hsi_np is not fed to the function, but it is loaded inside the function, we can't np.max(hsi_np, 0) to set negative values to 0,\n",
    "    which is a bit undesirable, so this function is meant to used mainly for quick experimentation purposes.\n",
    "    (Well, we could np.max(hsi_np, 0) inside this function but then we would also need that in the hsi_transform_to_pca_space() function.)\n",
    "\n",
    "    Parameters:\n",
    "    - hsi_path: str, path to the HSI file.\n",
    "    - pca: Pre-fitted PCA model.\n",
    "    - scaler: Pre-fitted StandardScaler model.\n",
    "    - mask_dir: str, path to the folder containing the masks for the HSI-s.\n",
    "    - apply_mask: bool, whether to apply the mask to the HSI-s.\n",
    "    - mask_method: int, 0 for keeping only leaf, 1 for keeping leaf+stem after applying the mask.\n",
    "\n",
    "    Returns:\n",
    "    - Plot (\"heatmap\") of the sum of reconstruction errors across the bands\n",
    "    \"\"\"\n",
    "    # Load a HSI\n",
    "    hsi_np = LoadHSI(hsi_path)\n",
    "    \n",
    "    # Load mask if required\n",
    "    if apply_mask and mask_dir:\n",
    "        mask_file = os.path.join(mask_dir, os.path.splitext(os.path.basename(hsi_path))[0] + \".png\")    # Find the mask for the HSI (same name)\n",
    "        mask_np = read_mask(mask_file)\n",
    "        mask_np = np.where(mask_np == 2, mask_method, mask_np)\n",
    "        \n",
    "    # Apply PCA and reconstruct\n",
    "    hsi_reconstructed = compress_and_reconstruct_hsi_pca(hsi_np, pca, scaler, mask_np, mask_method)\n",
    "    \n",
    "    # Compute reconstruction error\n",
    "    if apply_mask and mask_dir:\n",
    "        reconstruction_error = np.abs(hsi_np - hsi_reconstructed) * mask_np\n",
    "    else:\n",
    "        reconstruction_error = np.abs(hsi_np - hsi_reconstructed) \n",
    "        \n",
    "    # Sum reconstruction error across the bands\n",
    "    pixel_errors = np.sum(reconstruction_error, axis=0)\n",
    "\n",
    "    # Plot pixel errors\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(pixel_errors, cmap='hot')\n",
    "    plt.colorbar(label='Total Reconstruction Error')\n",
    "    plt.title('Total Reconstruction Error per Pixel')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_reconstruction_error(hsi_np, pca, scaler, mask_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_reconstruction_error_dir('../Data/HDF5_FILES/train/FX10_07SEPT2023_1B1.hdf5', pca, scaler\n",
    "                              , mask_dir='../Data/MASKS/train', apply_mask=True, mask_method=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize original img and img in PC space (first 3 bands/PCs) and reconstructed img (with 3 selected \"RGB\" bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi_np = np.maximum(hsi_np, 0)\n",
    "# hsi_np = hsi_np  / np.max(hsi_np)    # Could add this as well but then pca would need to be trained with individual_normalize=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi_reconstructed = compress_and_reconstruct_hsi_pca(hsi_np, pca, scaler, mask_np)\n",
    "hsi_pca = hsi_transform_to_pca_space(hsi_np, pca, scaler, mask_np=mask_np, mask_method=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find the bands corresponding to the RGB channels\n",
    "RGB_wlens = (445, 535, 575)\n",
    "RGB_bands = np.argmin(np.abs(np.array(wlens)[:, np.newaxis] - RGB_wlens), axis=0)\n",
    "print(f'RGB indices in hsi -> {RGB_bands}')\n",
    "\n",
    "# we create and RGB image from the hsi by selecting those bands, \n",
    "# but first set all negative values to 0 (these are noise) and normalize the hsi\n",
    "# hsi_np = np.maximum(hsi_np, 0)\n",
    "hsi_np = hsi_np  / np.max(hsi_np)\n",
    "\n",
    "# The pca space can easily have negative values and positives larger that 255. The reconstructed images should have values between 0 and 1 in\n",
    "# case hsi_np was already between 0 and 1, although we can expect that reconstruction is not perfect and some values might be outside this range.\n",
    "# Clipping the values between 0 and 1 is not that bad though for VISUALIZATION purposes. For VISUALIZATION PURPOSES only, we may also clip the\n",
    "# values in the PCA space between 0 and 1. (This should not be done e.g. at calculating the reconstruction error.)\n",
    "hsi_pca = np.maximum(hsi_pca, 0)\n",
    "hsi_pca = hsi_pca / np.max(hsi_pca)\n",
    "\n",
    "hsi_reconstructed = np.maximum(hsi_reconstructed, 0)\n",
    "hsi_reconstructed = hsi_reconstructed  / np.max(hsi_reconstructed)\n",
    "\n",
    "# select the rgb bands\n",
    "rgb_img = hsi_np[RGB_bands,:,]\n",
    "hsi_pca_img = hsi_pca[0:3,:,]\n",
    "rgb_img_reconstructed = hsi_reconstructed[RGB_bands,:,]\n",
    "print(f'shape, {rgb_img.shape}, but for other libraries usually the bands is the last dimension, so we change the order and get:')\n",
    "\n",
    "rgb_img = rgb_img.transpose((1,2,0))\n",
    "hsi_pca_img = hsi_pca_img.transpose((1,2,0))\n",
    "rgb_img_reconstructed = rgb_img_reconstructed.transpose((1,2,0))\n",
    "print(rgb_img.shape)\n",
    "\n",
    "#  now we can visualize the image\n",
    "plt.figure(figsize = (16,50))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rgb_img)\n",
    "plt.title('RGB')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(hsi_pca_img)\n",
    "plt.title('PCA reduced HSI')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(rgb_img_reconstructed)\n",
    "plt.title('Reconstructed RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe I saw somewhere that the PCA reduced HSI that is on the plot visualizes the parts with high(est) variance. It explains why we don't see a very clearly outlined image. We would need to add the average (or average + rescale?) to get a more meaningful image. Or something like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi_np.min(), hsi_np.max(), hsi_pca.min(), hsi_pca.max(), hsi_reconstructed.min(), hsi_reconstructed.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img.min(), rgb_img.max(), hsi_pca_img.min(), hsi_pca_img.max(), rgb_img_reconstructed.min(), rgb_img_reconstructed.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
